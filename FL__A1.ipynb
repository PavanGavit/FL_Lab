{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0Xtw5/OZoARSt3qIDsWoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PavanGavit/FL_Lab/blob/main/FL__A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LoggingFedAvg(fl.server.strategy.FedAvg):\n",
        "    def aggregate_evaluate(self, server_round, results, failures):\n",
        "        # Let Flower aggregate loss as usual\n",
        "        aggregated_loss, _ = super().aggregate_evaluate(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        # Manually aggregate accuracy (weighted by number of examples)\n",
        "        total_examples = 0\n",
        "        weighted_acc_sum = 0.0\n",
        "\n",
        "        for _, eval_res in results:\n",
        "            metrics = eval_res.metrics\n",
        "            if metrics and \"accuracy\" in metrics:\n",
        "                num_examples = eval_res.num_examples\n",
        "                weighted_acc_sum += metrics[\"accuracy\"] * num_examples\n",
        "                total_examples += num_examples\n",
        "\n",
        "        if total_examples > 0:\n",
        "            avg_accuracy = weighted_acc_sum / total_examples\n",
        "            print(\n",
        "                f\"[SERVER] Round {server_round} accuracy: {avg_accuracy:.4f}\"\n",
        "            )\n",
        "\n",
        "        return aggregated_loss, {}  # metrics already logged manually\n",
        "\n",
        "\n",
        "strategy = LoggingFedAvg(\n",
        "    min_fit_clients=2,\n",
        "    min_evaluate_clients=2,\n",
        "    min_available_clients=2,\n",
        ")\n",
        "\n",
        "fl.server.start_server(\n",
        "    server_address=\"0.0.0.0:8081\",\n",
        "    config=fl.server.ServerConfig(num_rounds=3),\n",
        "    strategy=strategy,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho8pCdKUwlz6",
        "outputId": "22ba502d-3f53-4fa5-c60d-a634b2f9d10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "import sys\n",
        "import flwr as fl\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "CLIENT_ID = int(sys.argv[1])\n",
        "NUM_CLIENTS = 2\n",
        "\n",
        "LOCAL_EPOCHS = {\n",
        "    0: 1,\n",
        "    1: 3,\n",
        "}\n",
        "\n",
        "\n",
        "def load_data(client_id: int, num_clients: int):\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "\n",
        "    shard_size = len(x_train) // num_clients\n",
        "    start = client_id * shard_size\n",
        "    end = start + shard_size\n",
        "\n",
        "    return (\n",
        "        x_train[start:end],\n",
        "        y_train[start:end],\n",
        "        x_test,\n",
        "        y_test,\n",
        "    )\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=(28, 28)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, client_id: int):\n",
        "        self.client_id = client_id\n",
        "        self.model = build_model()\n",
        "        self.x_train, self.y_train, self.x_test, self.y_test = load_data(\n",
        "            client_id, NUM_CLIENTS\n",
        "        )\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "\n",
        "        epochs = LOCAL_EPOCHS[self.client_id]\n",
        "\n",
        "        self.model.fit(\n",
        "            self.x_train,\n",
        "            self.y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=32,\n",
        "            verbose=0,\n",
        "        )\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "\n",
        "        loss, accuracy = self.model.evaluate(\n",
        "            self.x_test,\n",
        "            self.y_test,\n",
        "            verbose=0,\n",
        "        )\n",
        "\n",
        "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "client = FlowerClient(CLIENT_ID).to_client()\n",
        "\n",
        "fl.client.start_client(\n",
        "    server_address=\"127.0.0.1:8081\",\n",
        "    client=client,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbj9Bp3woL_",
        "outputId": "926de775-ee07-443d-a324-67a07235305b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import threading\n",
        "import sys\n",
        "\n",
        "\n",
        "def stream_output(pipe, prefix=\"\"):\n",
        "    for line in iter(pipe.readline, b\"\"):\n",
        "        print(prefix + line.decode(), end=\"\")\n",
        "\n",
        "\n",
        "# Start server with stdout captured\n",
        "server = subprocess.Popen(\n",
        "    [\"python\", \"server.py\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        ")\n",
        "\n",
        "# Stream server logs\n",
        "server_thread = threading.Thread(\n",
        "    target=stream_output,\n",
        "    args=(server.stdout, \"[SERVER] \"),\n",
        "    daemon=True,\n",
        ")\n",
        "server_thread.start()\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# Start client 0\n",
        "client0 = subprocess.Popen(\n",
        "    [\"python\", \"client.py\", \"0\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        ")\n",
        "\n",
        "client0_thread = threading.Thread(\n",
        "    target=stream_output,\n",
        "    args=(client0.stdout, \"[CLIENT 0] \"),\n",
        "    daemon=True,\n",
        ")\n",
        "client0_thread.start()\n",
        "\n",
        "time.sleep(1)\n",
        "\n",
        "# Start client 1 (foreground)\n",
        "client1 = subprocess.Popen(\n",
        "    [\"python\", \"client.py\", \"1\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        ")\n",
        "\n",
        "stream_output(client1.stdout, \"[CLIENT 1] \")\n",
        "\n",
        "# Cleanup\n",
        "client0.terminate()\n",
        "server.terminate()\n",
        "\n",
        "print(\"\\n✅ Training Complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG4lUhhLwqSX",
        "outputId": "ebfd020e-eb6b-40c8-c859-006a6bf91c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SERVER] \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.\n",
            "[SERVER] \tInstead, use the `flower-superlink` CLI command to start a SuperLink as shown below:\n",
            "[SERVER] \n",
            "[SERVER] \t\t$ flower-superlink --insecure\n",
            "[SERVER] \n",
            "[SERVER] \tTo view usage and all available options, run:\n",
            "[SERVER] \n",
            "[SERVER] \t\t$ flower-superlink --help\n",
            "[SERVER] \n",
            "[SERVER] \tUsing `start_server()` is deprecated.\n",
            "[SERVER] \n",
            "[SERVER]             This is a deprecated feature. It will be removed\n",
            "[SERVER]             entirely in future versions of Flower.\n",
            "[SERVER]         \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=3, no round_timeout\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      [INIT]\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "[CLIENT 0] 2026-01-21 09:30:51.910769: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "[CLIENT 0] 2026-01-21 09:30:51.920442: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "[CLIENT 0] 2026-01-21 09:30:51.955602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "[CLIENT 0] WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "[CLIENT 0] E0000 00:00:1768987852.016492   10204 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "[CLIENT 0] E0000 00:00:1768987852.034929   10204 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[CLIENT 0] W0000 00:00:1768987852.111711   10204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 0] W0000 00:00:1768987852.111852   10204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 0] W0000 00:00:1768987852.111885   10204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 0] W0000 00:00:1768987852.111907   10204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 0] 2026-01-21 09:30:52.130030: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "[CLIENT 0] To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[CLIENT 1] 2026-01-21 09:30:53.530244: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "[CLIENT 1] 2026-01-21 09:30:53.538517: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "[CLIENT 1] 2026-01-21 09:30:53.572744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "[CLIENT 1] WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "[CLIENT 1] E0000 00:00:1768987853.632499   10212 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "[CLIENT 1] E0000 00:00:1768987853.658542   10212 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[CLIENT 1] W0000 00:00:1768987853.715693   10212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 1] W0000 00:00:1768987853.715820   10212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 1] W0000 00:00:1768987853.715827   10212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 1] W0000 00:00:1768987853.715830   10212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[CLIENT 1] 2026-01-21 09:30:53.729717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "[CLIENT 1] To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[CLIENT 0] 2026-01-21 09:31:03.711179: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "[CLIENT 0] \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
            "[CLIENT 0] \tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
            "[CLIENT 0] \n",
            "[CLIENT 0] \t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
            "[CLIENT 0] \n",
            "[CLIENT 0] \tTo view all available options, run:\n",
            "[CLIENT 0] \n",
            "[CLIENT 0] \t\t$ flower-supernode --help\n",
            "[CLIENT 0] \n",
            "[CLIENT 0] \tUsing `start_client()` is deprecated.\n",
            "[CLIENT 0] \n",
            "[CLIENT 0]             This is a deprecated feature. It will be removed\n",
            "[CLIENT 0]             entirely in future versions of Flower.\n",
            "[CLIENT 0]         \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: get_parameters message 0a295d18-cda3-46fe-b656-72994b2f9f9e\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "[CLIENT 1] 2026-01-21 09:31:05.478772: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "[CLIENT 1] \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.\n",
            "[CLIENT 1] \tInstead, use the `flower-supernode` CLI command to start a SuperNode as shown below:\n",
            "[CLIENT 1] \n",
            "[CLIENT 1] \t\t$ flower-supernode --insecure --superlink='<IP>:<PORT>'\n",
            "[CLIENT 1] \n",
            "[CLIENT 1] \tTo view all available options, run:\n",
            "[CLIENT 1] \n",
            "[CLIENT 1] \t\t$ flower-supernode --help\n",
            "[CLIENT 1] \n",
            "[CLIENT 1] \tUsing `start_client()` is deprecated.\n",
            "[CLIENT 1] \n",
            "[CLIENT 1]             This is a deprecated feature. It will be removed\n",
            "[CLIENT 1]             entirely in future versions of Flower.\n",
            "[CLIENT 1]         \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: train message ba535104-a32f-4dc9-aa79-a635a19c4ef1\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: train message dc8921a9-9f54-41cf-95bd-578c4407edca\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "[SERVER] \u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: evaluate message 198bb732-0d3b-4834-9951-5eb5fe3194b8\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: evaluate message bd2faa11-60e3-4cb3-a4a9-ee64014baa53\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "[SERVER] \u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: train message 520096cd-0719-4f64-a912-8d44608a301c\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: train message eaf732e8-b604-4837-b4a3-e55747bb426e\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: evaluate message f8b4d691-93f3-484b-95a7-554252c8db21\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: evaluate message 9279721e-c8e0-479d-81c1-88badde58d2d\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: train message 77f8c87b-4add-4a4a-a64c-0334beb82716\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: train message cf5de3a1-f876-4846-bbd8-ea1ae5aa8ac1\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: evaluate message 1c764c97-ec07-46d6-adc6-df44b620d8c8\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: evaluate message d7a7dc90-c71f-4d41-a8e2-4e81f34ebdef\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Sent reply\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 47.42s\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \t\tround 1: 0.14385469257831573\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \t\tround 2: 0.09323737025260925\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \t\tround 3: 0.07662594318389893\n",
            "[SERVER] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Received: reconnect message d1120b2c-bf8a-4d72-83a7-3168d35e9c70\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      \n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Received: reconnect message 80105290-6ef2-43de-be35-c8a5e3f2ed9d\n",
            "[CLIENT 1] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
            "[CLIENT 0] \u001b[92mINFO \u001b[0m:      Disconnect and shut down\n",
            "[SERVER] [SERVER] Round 1 accuracy: 0.9563\n",
            "[SERVER] [SERVER] Round 2 accuracy: 0.9711\n",
            "[SERVER] [SERVER] Round 3 accuracy: 0.9763\n",
            "\n",
            "✅ Training Complete\n"
          ]
        }
      ]
    }
  ]
}